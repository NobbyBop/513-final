{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dae31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add imports here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ec1008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading and \"cleaning\" data\n",
    "df = pd.read_csv(\"California-Wildfire-Data.csv\")\n",
    "df_obj = df.select_dtypes(\"object\")\n",
    "\n",
    "df_obj.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fe562a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numeric data\n",
    "df_num = df.select_dtypes(\"number\")\n",
    "\n",
    "df_num[\"* Street Number\"] = df_num[\"* Street Number\"].replace(to_replace=0, value=np.nan)\n",
    "print(f\"Missing values in Street Number: {df_num[\"* Street Number\"].isna().sum()}\")\n",
    "\n",
    "df_num[\"Assessed Improved Value (parcel)\"] = df_num[\"Assessed Improved Value (parcel)\"].replace(to_replace=0, value=np.nan)\n",
    "print(f\"Missing values in Assessed Improved Value (parcel): {df_num[\"Assessed Improved Value (parcel)\"].isna().sum()}\")\n",
    "\n",
    "df_num[\"Year Built (parcel)\"] = df_num[\"Year Built (parcel)\"].replace(to_replace=0, value=np.nan)\n",
    "print(f\"Missing values in Year Built (parcel): {df_num[\"Year Built (parcel)\"].isna().sum()}\")\n",
    "\n",
    "df_num = df_num.dropna()\n",
    "print(f\"Rows remaining after dropping na: {len(df_num.index)}\")\n",
    "\n",
    "df_num.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0df336",
   "metadata": {},
   "source": [
    "# Exploritory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4zus7w80qn8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploratory Data Analysis\n",
    "for col in df_obj.columns:\n",
    "    unique_vals = df_obj[col].unique()\n",
    "    n_unique = len(unique_vals)\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"Number of unique values: {n_unique}\")\n",
    "    if \"unknown\" in list(unique_vals):\n",
    "        print(f\"Number of missing values: {0 + df_obj[col].value_counts()[\"unknown\"]}\")\n",
    "    if \"Unknown\" in list(unique_vals):\n",
    "        print(f\"Number of missing values: {0 + df_obj[col].value_counts()[\"Unknown\"]}\")\n",
    "    if n_unique <= 20:\n",
    "        print(f\"Values: {list(unique_vals)}\")\n",
    "    else:\n",
    "        print(f\"Sample values (first 20): {list(unique_vals[:20])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628a869e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_num.columns:\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"Mean: {df_num[col].mean():.2f}\")\n",
    "    print(f\"Median: {df_num[col].median():.2f}\")\n",
    "    mode_vals = df_num[col].mode()\n",
    "    if len(mode_vals) > 0:\n",
    "        print(f\"Mode: {mode_vals[0]:.2f}\")\n",
    "    else:\n",
    "        print(f\"Mode: N/A\")\n",
    "    print(f\"Std Dev: {df_num[col].std():.2f}\")\n",
    "    print(f\"Min: {df_num[col].min():.2f}\")\n",
    "    print(f\"Max: {df_num[col].max():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf9682c",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffc6be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c789ef99",
   "metadata": {},
   "source": [
    "# CART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce34b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a label encoder here because using the get_dummies() method takes too much memory and crashes the kernel.\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df_encoded = df_obj.copy()\n",
    "le_target = LabelEncoder()\n",
    "\n",
    "# Fit and save the target encoder\n",
    "le_target.fit(df_obj['* Damage'].astype(str))\n",
    "\n",
    "# Encode all columns\n",
    "for col in df_encoded.columns:\n",
    "    df_encoded[col] = LabelEncoder().fit_transform(df_encoded[col].astype(str))\n",
    "\n",
    "attr = df_encoded.drop(['* Damage'], axis=1)\n",
    "target = df_encoded['* Damage']\n",
    "\n",
    "attr_train, attr_test, target_train, target_test = train_test_split(attr, target, test_size=0.3, random_state=6)\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(attr_train, target_train)\n",
    "target_pred = model.predict(attr_test)\n",
    "\n",
    "# Decode predictions and targets\n",
    "target_test_decoded = le_target.inverse_transform(target_test)\n",
    "target_pred_decoded = le_target.inverse_transform(target_pred)\n",
    "\n",
    "# Get class labels\n",
    "labels = le_target.classes_\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(target_test_decoded, target_pred_decoded, labels=labels)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix - CART')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(target_test_decoded, target_pred_decoded))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cc43b2",
   "metadata": {},
   "source": [
    "Using the CART method, we see that our model is 88% accurate. We can also see that most of our data either falls into \"No Damage\" or \"Destroyed\". There is significantly less data for any other categories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d39d58f",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e6b10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff80bd5e",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d769a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22767b6",
   "metadata": {},
   "source": [
    "# ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb489530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc540d3",
   "metadata": {},
   "source": [
    "# HClust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedeb4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43af42bc",
   "metadata": {},
   "source": [
    "# KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc25d87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
