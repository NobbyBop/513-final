{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dae31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add imports here\n",
    "!pip install imbalanced-learn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ec1008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading and \"cleaning\" data\n",
    "df = pd.read_csv(\"California-Wildfire-Data.csv\")\n",
    "df_obj = df.select_dtypes(\"object\")\n",
    "\n",
    "df_obj.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fe562a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numeric data\n",
    "df_num = df.select_dtypes(\"number\")\n",
    "\n",
    "df_num[\"* Street Number\"] = df_num[\"* Street Number\"].replace(to_replace=0, value=np.nan)\n",
    "print(f\"Missing values in Street Number: {df_num[\"* Street Number\"].isna().sum()}\")\n",
    "\n",
    "df_num[\"Assessed Improved Value (parcel)\"] = df_num[\"Assessed Improved Value (parcel)\"].replace(to_replace=0, value=np.nan)\n",
    "print(f\"Missing values in Assessed Improved Value (parcel): {df_num[\"Assessed Improved Value (parcel)\"].isna().sum()}\")\n",
    "\n",
    "df_num[\"Year Built (parcel)\"] = df_num[\"Year Built (parcel)\"].replace(to_replace=0, value=np.nan)\n",
    "print(f\"Missing values in Year Built (parcel): {df_num[\"Year Built (parcel)\"].isna().sum()}\")\n",
    "\n",
    "df_num = df_num.dropna()\n",
    "print(f\"Rows remaining after dropping na: {len(df_num.index)}\")\n",
    "\n",
    "df_num.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0df336",
   "metadata": {},
   "source": [
    "# Exploritory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4zus7w80qn8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploratory Data Analysis\n",
    "for col in df_obj.columns:\n",
    "    unique_vals = df_obj[col].unique()\n",
    "    n_unique = len(unique_vals)\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"Number of unique values: {n_unique}\")\n",
    "    if \"unknown\" in list(unique_vals):\n",
    "        print(f\"Number of missing values: {0 + df_obj[col].value_counts()[\"unknown\"]}\")\n",
    "    if \"Unknown\" in list(unique_vals):\n",
    "        print(f\"Number of missing values: {0 + df_obj[col].value_counts()[\"Unknown\"]}\")\n",
    "    if n_unique <= 20:\n",
    "        print(f\"Values: {list(unique_vals)}\")\n",
    "    else:\n",
    "        print(f\"Sample values (first 20): {list(unique_vals[:20])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628a869e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_num.columns:\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"Mean: {df_num[col].mean():.2f}\")\n",
    "    print(f\"Median: {df_num[col].median():.2f}\")\n",
    "    mode_vals = df_num[col].mode()\n",
    "    if len(mode_vals) > 0:\n",
    "        print(f\"Mode: {mode_vals[0]:.2f}\")\n",
    "    else:\n",
    "        print(f\"Mode: N/A\")\n",
    "    print(f\"Std Dev: {df_num[col].std():.2f}\")\n",
    "    print(f\"Min: {df_num[col].min():.2f}\")\n",
    "    print(f\"Max: {df_num[col].max():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf9682c",
   "metadata": {},
   "source": [
    "# KNN\n",
    "K-Nearest Neighbors (KNN) is a distance-based classifier that predicts damage by finding the most similar examples in the training set; here, we use SMOTE to balance the classes and `weights='distance'` to prioritize closer neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffc6be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN Implementation with SMOTE, Scaling and Best Params\n",
    "import os\n",
    "os.environ['LOKY_MAX_CPU_COUNT'] = '1'\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Prepare data\n",
    "df_encoded = df_obj.copy()\n",
    "le_target = LabelEncoder()\n",
    "df_encoded['* Damage'] = le_target.fit_transform(df_encoded['* Damage'].astype(str))\n",
    "\n",
    "# Encode other columns\n",
    "for col in df_encoded.columns:\n",
    "    if col != '* Damage':\n",
    "        df_encoded[col] = LabelEncoder().fit_transform(df_encoded[col].astype(str))\n",
    "\n",
    "attr = df_encoded.drop(['* Damage'], axis=1)\n",
    "target = df_encoded['* Damage']\n",
    "\n",
    "# Split\n",
    "attr_train, attr_test, target_train, target_test = train_test_split(attr, target, test_size=0.3, random_state=6)\n",
    "\n",
    "# Apply SMOTE to Training Data Only\n",
    "print(\"Applying SMOTE to training data...\")\n",
    "smote = SMOTE(random_state=42)\n",
    "attr_train_res, target_train_res = smote.fit_resample(attr_train, target_train)\n",
    "\n",
    "# Round to nearest int to keep categorical nature valid\n",
    "attr_train_res = np.round(attr_train_res).astype(int)\n",
    "\n",
    "# Scaling (Fit on Resampled Training Data)\n",
    "scaler = MinMaxScaler()\n",
    "attr_train_scaled = scaler.fit_transform(attr_train_res)\n",
    "attr_test_scaled = scaler.transform(attr_test)\n",
    "\n",
    "# Grid Search (Commented out as requested)\n",
    "# print(\"Starting Grid Search for KNN...\")\n",
    "# param_grid = {'n_neighbors': [3, 5, 7, 9], 'weights': ['uniform', 'distance']}\n",
    "# grid_knn = GridSearchCV(KNeighborsClassifier(), param_grid, cv=3, n_jobs=1, verbose=1)\n",
    "# grid_knn.fit(attr_train_scaled, target_train_res)\n",
    "# print(f\"Best KNN Parameters: {grid_knn.best_params_}\")\n",
    "# target_pred = grid_knn.predict(attr_test_scaled)\n",
    "\n",
    "# Using Best Parameters directly\n",
    "print(\"Training KNN with best parameters (n_neighbors=3, weights='distance')...\")\n",
    "knn = KNeighborsClassifier(n_neighbors=3, weights='distance')\n",
    "knn.fit(attr_train_scaled, target_train_res)\n",
    "target_pred = knn.predict(attr_test_scaled)\n",
    "\n",
    "# Decode for report\n",
    "target_test_decoded = le_target.inverse_transform(target_test)\n",
    "target_pred_decoded = le_target.inverse_transform(target_pred)\n",
    "labels = le_target.classes_\n",
    "\n",
    "# Evaluation\n",
    "print(\"KNN Classification Report (with SMOTE):\")\n",
    "print(classification_report(target_test_decoded, target_pred_decoded))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(target_test_decoded, target_pred_decoded, labels=labels)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "plt.title('Confusion Matrix - KNN (SMOTE + Best Params)')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c789ef99",
   "metadata": {},
   "source": [
    "# CART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce34b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a label encoder here because using the get_dummies() method takes too much memory and crashes the kernel.\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df_encoded = df_obj.copy()\n",
    "le_target = LabelEncoder()\n",
    "\n",
    "# Fit and save the target encoder\n",
    "le_target.fit(df_obj['* Damage'].astype(str))\n",
    "\n",
    "# Encode all columns\n",
    "for col in df_encoded.columns:\n",
    "    df_encoded[col] = LabelEncoder().fit_transform(df_encoded[col].astype(str))\n",
    "\n",
    "attr = df_encoded.drop(['* Damage'], axis=1)\n",
    "target = df_encoded['* Damage']\n",
    "\n",
    "attr_train, attr_test, target_train, target_test = train_test_split(attr, target, test_size=0.3, random_state=6)\n",
    "\n",
    "# Added class_weight='balanced' to handle class imbalance\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(attr_train, target_train)\n",
    "target_pred = model.predict(attr_test)\n",
    "\n",
    "# Decode predictions and targets\n",
    "target_test_decoded = le_target.inverse_transform(target_test)\n",
    "target_pred_decoded = le_target.inverse_transform(target_pred)\n",
    "\n",
    "# Get class labels\n",
    "labels = le_target.classes_\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(target_test_decoded, target_pred_decoded, labels=labels)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix - CART (Balanced)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(target_test_decoded, target_pred_decoded))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cc43b2",
   "metadata": {},
   "source": [
    "Using the CART method, we see that our model is 88% accurate. We can also see that most of our data either falls into \"No Damage\" or \"Destroyed\". There is significantly less data for any other categories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d39d58f",
   "metadata": {},
   "source": [
    "# Naive Bayes\n",
    "Naive Bayes is a probabilistic classifier based on Bayes' theorem; we use `CategoricalNB` suitable for our labeled data and apply SMOTE to improve the detection of rare damage categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e6b10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes Implementation with SMOTE and Best Params\n",
    "import os\n",
    "os.environ['LOKY_MAX_CPU_COUNT'] = '1'\n",
    "\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "\n",
    "# Calculate min_categories from the full dataset to avoid IndexError\n",
    "min_categories = [attr[col].max() + 1 for col in attr.columns]\n",
    "\n",
    "# Apply SMOTE (Re-applying here to be self-contained)\n",
    "smote = SMOTE(random_state=42)\n",
    "attr_train_res, target_train_res = smote.fit_resample(attr_train, target_train)\n",
    "attr_train_res = np.round(attr_train_res).astype(int)\n",
    "\n",
    "# Grid Search (Commented out as requested)\n",
    "# print(\"Starting Grid Search for Naive Bayes...\")\n",
    "# param_grid = {'alpha': [0.1, 0.5, 1.0, 2.0]}\n",
    "# grid_nb = GridSearchCV(CategoricalNB(min_categories=min_categories), param_grid, cv=3, n_jobs=1, verbose=1)\n",
    "# grid_nb.fit(attr_train_res, target_train_res)\n",
    "# print(f\"Best NB Parameters: {grid_nb.best_params_}\")\n",
    "# target_pred_nb = grid_nb.predict(attr_test)\n",
    "\n",
    "# Using Best Parameters directly\n",
    "print(\"Training Naive Bayes with best parameters (alpha=1.0)...\")\n",
    "nb = CategoricalNB(alpha=1.0, min_categories=min_categories)\n",
    "nb.fit(attr_train_res, target_train_res)\n",
    "target_pred_nb = nb.predict(attr_test)\n",
    "\n",
    "# Decode\n",
    "target_pred_nb_decoded = le_target.inverse_transform(target_pred_nb)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Naive Bayes Classification Report (with SMOTE):\")\n",
    "print(classification_report(target_test_decoded, target_pred_nb_decoded))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm_nb = confusion_matrix(target_test_decoded, target_pred_nb_decoded, labels=labels)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm_nb, annot=True, fmt='d', cmap='Greens', xticklabels=labels, yticklabels=labels)\n",
    "plt.title('Confusion Matrix - Naive Bayes (SMOTE + Best Params)')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff80bd5e",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d769a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22767b6",
   "metadata": {},
   "source": [
    "# ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb489530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc540d3",
   "metadata": {},
   "source": [
    "# HClust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedeb4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43af42bc",
   "metadata": {},
   "source": [
    "# KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc25d87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}